---
title: 'FZ-J WWTP ATS Pilot'
subtitle: 'Data Cleaning'
author:
- Dean Calahan^[Smithsonian Institution]
- Isabel Meuser^[Forschungszentrum Jülich]
- Ladislav Nedbal^[Forschungszentrum Jülich]
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.height=3)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```
```{r initialize}
source("Code/R/Settings.R")
source("Code/R/FZJWWTPP.R")
```
# Introduction  
Here we clean the data from the 2018 ATS pilot at Forschungszentrum-Jülich and generate
csv files for general consumption. Temperature and illumination data were downloaded
weekly from a HOBO data logger. Water quality data was obtained by using standardized
kits. Biomass productivity data was obtained by weighing wet and dried biomass harvested
from a defined portion of the floway surface. Water quality and biomass data were
entered manually into the spreadsheet `ATS Treatment.xlsx`. Biomass composition
data was obtained by standard analyses and stored in the spreadsheet `Analysen ZEA-3.xlsx`.

To clean the temperature and illumination data, each week's data file (`ATS_<#.dd.mm.yy>.hobo`)
was converted csv using the Onset's HOBOware software (note that the files `*.hproj`
contain metadata bout the `.hobo` files and were not processed). Because the data
loggers were either initialized in an office before being transported to the floway
for installation, or downloaded after being removed from the floway and taken to
the office, the initial and final observations had to be discarded. Figures 1-7
and the code that generated them show which observations were discarded. The remaining
observations were combined into a single data set and saved as a csv file. To clean
the water quality and biomass data, recorded manually in an Excel spreadsheet, the
spreadsheet data were loaded and manipulated into a schema more useful for analysis
before being saved as a csv file.

# Data Descriptions
## Temperature and Illumination
Each week's data is shown in several views, for both illumination and temperature.
First the entire data set is shown, with vertical blue lines indicating either the
earliest observation that was retained (right hand side) or the latest observation
that was retained (left hand side). This global view is followed by a magnification
of the early and late regions. The numbers in the function call that performs the
data cleaning refer to how many observations are removed from the beginning and
end of the data set, respectively.

## Water Quality, Biomass Productivity, Biomass Composition
Some of the columns of `ATS Treatment.xlsx` ("Dilution PO4-P", "PO4-P", "reduction",
"Dilution TNb", "TNb", "remark"), were not retained in the cleaned data, while others
(unnamed column with "before/after", "commend") were converted from text to logical
for improved ease of analysis. All of the columns of `Analysen ZEA-3.xlsx` were
retained.

\newpage
## Week 1 (ATS_1)  
```{r week1, echo = TRUE}
# Create initial cleaned data set
ti_df <- CleanHOBOData(HOBO_fn[1], 1010, 365, w=1)
```

## Week 2 (ATS_2)  
```{r week2, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[2], 9773, 271, w=2))
```

## Week 3 (ATS_1)  
```{r week3, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[3], 119, 96, w=3))
```

## Week 4 (ATS_2)  
```{r week4, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[4], 107, 227, w=4))
```

## Week 5 (ATS_1)  
```{r week5, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[5], 107, 227, w=5))
```

## Week 6 (ATS_2)  
```{r week6, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[6], 121, 65, w=6))
```

## Week 7 (ATS_1)  
```{r week7, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[7], 84, 54, w=7))
```
```{r save_ti}
# Save the data set as a csv file
write_csv(ti_df, ti_fn)
```

# Floway Chemistry & Biomass Productivity
On two occasions, samples were assayed both on the day they were taken and after
freezing (Table 1). As the absolute differences between the readings for frozen
and unfrozen samples was small, less than 5% except for two measurements, it was
decided to freeze and accumulate samples for collective analysis rather than assay
each sample on the day it was collected.  

```{r WaterQualityBiomass}
# Load the data in the Excel spreadsheet into a temporary data frame
# t_df <- read_excel(sswc_fn,
#                    sheet="Tabelle1",
#                    skip=3,
#                    col_names=c("date",
#                                "time",
#                                "beforeafter",
#                                "PO4dil",
#                                "PO4P",
#                                "PO4Pxdil",
#                                "PO4Pred",
#                                "dilTN",
#                                "TNxdil",
#                                "TN",
#                                "TNred",
#                                "comment",
#                                "remark",
#                                "assaydate",
#                                "bmwet",
#                                "bmdry",
#                                "bmdrypct",
#                                "pH"))
t_df <- WaterQualityBiomass()
# Impute missing times. We take the earliest time, and simply add 24 hours to it
# [todo] Is this even used? There is something wrong here at any rate
no_times <- which(is.na(t_df$time))
min_time <- min(ti_df[ti_df$week == 1,]$datetime)
t_df[which(is.na(t_df$time)),]$time <- make_datetime(2018,
                                                     12,
                                                     31,
                                                     8,
                                                     0,
                                                     0)

# Create a new data frame with date and time combined into datetime for each observation
wcb_df <- data.frame(datetime=make_datetime(year(t_df$date),
                                            month(t_df$date),
                                            day(t_df$date),
                                            hour(t_df$time),
                                            minute(t_df$time),
                                            second(t_df$time),
                                            tz="Europe/Berlin"))

# Make before/after a logical
wcb_df$before <- TRUE
wcb_df[which(t_df$beforeafter != "before"),]$before <- FALSE

# Nutrient concentrations & pH
wcb_df$PO4P <- t_df$PO4Pxdil
wcb_df$TN <- t_df$TN
wcb_df$pH <- t_df$pH

# Make frozen/not frozen a logical
wcb_df$frozen <- TRUE
wcb_df[which(t_df$comment != "frozen"),]$frozen <- FALSE

# Date of assay
wcb_df$assaydate <- make_date(year(t_df$assaydate),
                              month(t_df$assaydate),
                              day(t_df$assaydate))

# Biomass measurements
wcb_df$wet_biomass <- t_df$bmwet
wcb_df$dry_biomass <- t_df$bmdry
wcb_df$solids <- t_df$bmdrypct

# Need observation date separate from datetime to make life easier
wcb_df$obsdate <- make_date(year(wcb_df$datetime), month(wcb_df$datetime), day(wcb_df$datetime))
```
```{r RemoveDupes}
# Remove non-frozen duplicates
dupe_df <- wcb_df[c(3:6, 13:16),] %>% select(datetime, before, PO4P, TN, frozen)
dupedeltas_df <- data.frame(before = c(FALSE, TRUE, FALSE, TRUE),
                            PO4Pdelta = c(dupe_df[2,]$PO4P - dupe_df[1,]$PO4P,
                                          dupe_df[4,]$PO4P - dupe_df[3,]$PO4P,
                                          dupe_df[6,]$PO4P - dupe_df[5,]$PO4P,
                                          dupe_df[8,]$PO4P - dupe_df[7,]$PO4P),
                            TNdelta = c(dupe_df[2,]$TN - dupe_df[1,]$TN,
                                          dupe_df[4,]$TN - dupe_df[3,]$TN,
                                          dupe_df[6,]$TN - dupe_df[5,]$TN,
                                          dupe_df[8,]$TN - dupe_df[7,]$TN))
dupedeltas_df$PO4Ppct <- 100*dupedeltas_df$PO4Pdelta/dupe_df[c(2, 4, 6, 8),]$PO4P
dupedeltas_df$TNpct <- 100*dupedeltas_df$TNdelta/dupe_df[c(2, 4, 6, 8),]$TN
kable(dupedeltas_df)
```
```{r save_cb}
wcb_df <- wcb_df[c(1:2, 4, 6:12, 14, 16:55),]
write_csv(wcb_df, wcb_fn)
```
# Biomass Composition
```{r BiomassCompositionData}
atoms <- c("C", "Ca", "K","Mg", "Mn", "N", "P", "S")
masses <- setNames(mass(atoms), atoms)

bc_df <- read_excel(ssbc_fn,
                   sheet="Tabelle1",
                   skip=18,
                   col_names=c("id",
                               "date",
                               "Smw",
                               "Ssd",
                               "Pmw",
                               "Psd",
                               "Kmw",
                               "Ksd",
                               "Camw",
                               "Casd",
                               "Mgmw",
                               "Mgsd",
                               "Mnmw",
                               "Mnsd",
                               "Cmw",
                               "Csd",
                               "Nmw",
                               "Nsd"))


val_cols <- c("Cmw", "Nmw", "Mgmw", "Pmw", "Smw", "Kmw", "Camw", "Mnmw")
sel_cols <- c("date", "reading", "val")

# "NAs introduced by coercion" warning is OK.
sd <- suppressWarnings(as.numeric(with(bc_df, c(Csd, Nsd, Mgsd, Psd, Ssd, Ksd, Casd, Mnsd))))

bc_plot_df <- bc_df %>%
    gather_(key="reading", value="val", gather_cols=val_cols) %>%
    select(sel_cols)
bc_plot_df$sd <- sd
```

```{r BiomassCompositionPlots}
# Plot weight percents of biomass composition readings with their standard deviations.
ggplot(bc_plot_df, aes(x=date, y=val, fill=reading)) +
    geom_bar(stat="identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=val-sd, ymax=val+sd), 
                  position=position_dodge(),
                  na.rm=TRUE)

# Plot means of the biomasscomposition readings
bc_mean_df <- bc_df %>% summarize(Cmean = mean(Cmw, na.rm=TRUE), Csd = sd(Cmw, na.rm=TRUE),
                    Nmean = mean(Nmw), Nsd = sd(Nmw),
                    Mgmean = mean(Mgmw), Mgsd = sd(Mgmw),
                    Pmean = mean(Pmw), Psd = sd(Pmw),
                    Smean = mean(Smw), Ssd = sd(Smw),
                    Kmean = mean(Kmw), Ksd = sd(Kmw),
                    Camean = mean(Camw), Casd = sd(Camw),
                    Mnmean = mean(Mnmw), Mnsd = sd(Mnmw))

val_cols <- c("Cmean", "Nmean", "Mgmean", "Pmean", "Smean", "Kmean", "Camean", "Mnmean")
sd <- with(bc_mean_df, c(Csd, Nsd, Mgsd, Psd, Ssd, Ksd, Csd, Mnsd))
sel_cols <- c("reading", "val")

bc_mean_plot_df <- bc_mean_df %>%
    gather_(key="reading", value="val", val_cols) %>%
    select(sel_cols)

ggplot(bc_mean_plot_df, aes(x=reading, y=val)) +
    geom_bar(stat="identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=val-sd, ymax=val+sd), 
                  position=position_dodge())

# Molar ratios
moles <- with(bc_mean_df, c(Cmean, Nmean, Mgmean, Pmean, Smean, Kmean, Camean, Mnmean))/
    sort(masses)

```
# Appendix  

## Data Dictionaries