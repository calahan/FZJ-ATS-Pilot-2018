---
title: 'FZ-J WWTP ATS Pilot'
subtitle: 'Data Cleaning'
author:
- Dean Calahan^[Smithsonian Institution]
- Isabel Meuser^[Forschungszentrum Jülich]
- Ladislav Nedbal^[Forschungszentrum Jülich]
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.height=3)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```
```{r initialize}
library(readr)
library(readxl)
library(dplyr)
library(lubridate)
library(knitr)
source("Code/R/Settings.R")
source("Code/R/FZJWWTPP.R")
```
# Introduction  
Here we clean the data by reading the data files, manipulating the data to better
organize it for analysis, then saving the reoragnized data as csv files. Temperature
and illumination data were downloaded weekly from a HOBO data logger. Water quality and
biomass data were entered manually into a spreadsheet.

To clean the temperature and illumination data, each week's data file (`ATS_<#.dd.mm.yy>.hobo`)
was converted csv using the Onset's HOBOware software (note that the files `*.hproj`
contain metadata bout the `.hobo` files and were not processed). Because the data
loggers were either initialized in an office before being transported to the floway
for installation, or downloaded after being removed from the floway and taken to
the office, the initial and final observations had to be discarded. Figures 1-7
and the code that generated them show which observations were discarded. The remaining
observations were combined into a single data set and saved as a csv file. To clean
the water quality and biomass data, recorded manually in an Excel spreadsheet, the
spreadsheet data were loaded and manipulated into a schema more useful for analysis
before being saved as a csv file.

# Temperature and Illumination  
Each week's data is shown in several views, for both illumination and temperature.
First the entire data set is shown, with vertical blue lines indicating either the
earliest observation that was retained (right hand side) or the latest observation
that was retained (left hand side). This global view is followed by a magnification
of the early and late regions. The numbers in the function call that performs the
data cleaning refer to how many observations are removed from the beginning and
end of the data set, respectively.

# Water Quality and Biomass Productivity
Some of the columns ("Dilution PO4-P", "PO4-P", "reduction", "Dilution TNb", "TNb",
"remark"), were not retained in the cleaned data, while others (unnamed column with
"before/after", "commend") were converted from text to logical for improved ease of
analysis.

# Biomass Composition
Here we access a separate spreadsheet.

\newpage
## Week 1 (ATS_1)  
```{r week1, echo = TRUE}
# Create initial cleaned data set
ti_df <- CleanHOBOData(HOBO_fn[1], 1010, 365, w=1)
```

## Week 2 (ATS_2)  
```{r week2, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[2], 9773, 271, w=2))
```

## Week 3 (ATS_1)  
```{r week3, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[3], 119, 96, w=3))
```

## Week 4 (ATS_2)  
```{r week4, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[4], 107, 227, w=4))
```

## Week 5 (ATS_1)  
```{r week5, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[5], 107, 227, w=5))
```

## Week 6 (ATS_2)  
```{r week6, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[6], 121, 65, w=6))
```

## Week 7 (ATS_1)  
```{r week7, echo = TRUE}
# Clean and append the next data set
ti_df <- ti_df %>% rbind(CleanHOBOData(HOBO_fn[7], 84, 54, w=7))
```
```{r save_ti}
# Save the data set as a csv file
write_csv(ti_df, ti_fn)
```

# Floway Chemistry & Biomass Productivity
On two occasions, samples were assayed both on the day they were taken and after
freezing (Table 1). As the absolute differences between the readings for frozen
and unfrozen samples was small, less than 5% except for two measurements, it was
decided to freeze and accumulate samples for collective analysis rather than assay
each sample on the day it was collected.
```{r WaterQualityBiomass}
# Load the data in the Excel spreadsheet into a temporary data frame
t_df <- read_excel(ss_fn,
                   sheet="Tabelle1",
                   skip=3,
                   col_names=c("date",
                               "time",
                               "beforeafter",
                               "PO4dil",
                               "PO4P",
                               "PO4Pxdil",
                               "PO4Pred",
                               "dilTN",
                               "TNxdil",
                               "TN",
                               "TNred",
                               "comment",
                               "remark",
                               "assaydate",
                               "bmwet",
                               "bmdry",
                               "bmdrypct",
                               "pH"))

# Impute missing times. We take the earliest time, and simply add 24 hours to it
# [todo] Is this even used? There is something wrong here at any rate
no_times <- which(is.na(t_df$time))
min_time <- min(ti_df[ti_df$week == 1,]$datetime)
t_df[which(is.na(t_df$time)),]$time <- make_datetime(2018,
                                                     12,
                                                     31,
                                                     8,
                                                     0,
                                                     0)

# Create a new data frame with date and time combined into datetime for each observation
wqb_df <- data.frame(datetime=make_datetime(year(t_df$date),
                                            month(t_df$date),
                                            day(t_df$date),
                                            hour(t_df$time),
                                            minute(t_df$time),
                                            second(t_df$time),
                                            tz="Europe/Berlin"))

# Make before/after a logical
wqb_df$before <- TRUE
wqb_df[which(t_df$beforeafter != "before"),]$before <- FALSE

# Nutrient concentrations & pH
wqb_df$PO4P <- t_df$PO4Pxdil
wqb_df$TN <- t_df$TN
wqb_df$pH <- t_df$pH

# Make frozen/not frozen a logical
wqb_df$frozen <- TRUE
wqb_df[which(t_df$comment != "frozen"),]$frozen <- FALSE

# Date of assay
wqb_df$assaydate <- make_date(year(t_df$assaydate),
                              month(t_df$assaydate),
                              day(t_df$assaydate))

# Biomass measurements
wqb_df$wet_biomass <- t_df$bmwet
wqb_df$dry_biomass <- t_df$bmdry
wqb_df$solids <- t_df$bmdrypct

# Need observation date separate from datetime to make life easier
wqb_df$obsdate <- make_date(year(wqb_df$datetime), month(wqb_df$datetime), day(wqb_df$datetime))
```
```{r RemoveDupes}
# Remove non-frozen duplicates
dupe_df <- wqb_df[c(3:6, 13:16),] %>% select(datetime, before, PO4P, TN, frozen)
dupedeltas_df <- data.frame(before = c(FALSE, TRUE, FALSE, TRUE),
                            PO4Pdelta = c(dupe_df[2,]$PO4P - dupe_df[1,]$PO4P,
                                          dupe_df[4,]$PO4P - dupe_df[3,]$PO4P,
                                          dupe_df[6,]$PO4P - dupe_df[5,]$PO4P,
                                          dupe_df[8,]$PO4P - dupe_df[7,]$PO4P),
                            TNdelta = c(dupe_df[2,]$TN - dupe_df[1,]$TN,
                                          dupe_df[4,]$TN - dupe_df[3,]$TN,
                                          dupe_df[6,]$TN - dupe_df[5,]$TN,
                                          dupe_df[8,]$TN - dupe_df[7,]$TN))
dupedeltas_df$PO4Ppct <- 100*dupedeltas_df$PO4Pdelta/dupe_df[c(2, 4, 6, 8),]$PO4P
dupedeltas_df$TNpct <- 100*dupedeltas_df$TNdelta/dupe_df[c(2, 4, 6, 8),]$TN
kable(dupedeltas_df)
```
```{r save_cb}
wqb_df <- wqb_df[c(1:2, 4, 6:12, 14, 16:55),]
write_csv(wqb_df, wqb_fn)
```
# Biomass Composition
```{r BiomassComposition}
bc_df <- read_excel(bcss_fn,
                   sheet="Tabelle1",
                   skip=18,
                   col_names=c("id",
                               "date",
                               "Smw",
                               "Ssd",
                               "Pmw",
                               "Psd",
                               "Kmw",
                               "Ksd",
                               "Camw",
                               "Casd",
                               "Mgmw",
                               "Mgsd",
                               "Mnmw",
                               "Mnsd",
                               "Cmmw",
                               "Csd",
                               "Nmw",
                               "Nsd"))
```